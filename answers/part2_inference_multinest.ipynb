{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25423df-7eb4-4876-9692-56834a98f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyparallel import Client\n",
    "rc = Client(profile='mpi')\n",
    "# Grab a view\n",
    "view = rc[:]\n",
    "\n",
    "# Activate parallel cell magics\n",
    "view.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaaa077-0b8d-4571-a611-5901f7fb2b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AsyncResult(%px): pending>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%px\n",
    "    import numpy as np\n",
    "    from pymultinest import run\n",
    "    import scipy\n",
    "    import tensorflow.compat.v1 as tf\n",
    "    import time, os\n",
    "    \n",
    "    os.chdir('notebooks/ai4astro/')\n",
    "    emulator = tf.keras.models.load_model('emulator')\n",
    "\n",
    "    # define the meaning for the features, i.e. your model parameters\n",
    "    parameters = np.array([r\"$\\log_{10} f_{*,10}$\",\n",
    "                           r\"$\\alpha_*$\",\n",
    "                           r\"$\\log_{10} f_{\\rm esc, 10}$\",\n",
    "                           r\"$\\alpha_{\\rm esc}$\",\n",
    "                           r\"$\\log_{10}[M_{\\rm turn}/{\\rm M}_{\\odot}]$\",\n",
    "                           r\"$t_*$\",\n",
    "                           r\"$\\log_{10}\\frac{L_{\\rm X<2keV}/{\\rm SFR}}{{\\rm erg\\ s^{-1}\\ M_{\\odot}^{-1}\\ yr}}$\",\n",
    "                           r\"$E_0/{\\rm keV}$\",\n",
    "                           r\"$\\alpha_{\\rm X}$\"])\n",
    "\n",
    "    # and their limits\n",
    "    limits = np.array([[-3,0], [-0.5,1], [-3,0],[-1,0.5], [8,10], [0.01,1], [38,42], [0.1,1.5], [-1,3]])\n",
    "\n",
    "    def Prior(cube, ndim, nparams):\n",
    "        return cube\n",
    "\n",
    "    def log_likelihood(cube, ndim, nparams):\n",
    "        theta = np.zeros(ndim)\n",
    "        for i in range(ndim):\n",
    "            theta[i] = cube[i]\n",
    "        model = emulator.predict(theta.reshape([1,-1]),verbose=False)[0]\n",
    "        total_sum = 0\n",
    "        current_index = 0\n",
    "\n",
    "        # neutral fraction\n",
    "        McGreer_NF = model[current_index]\n",
    "        current_index+=1\n",
    "        if McGreer_NF>1.: \n",
    "            McGreer_NF=1 # physical prior\n",
    "\n",
    "        McGreer_Mean = 0.06\n",
    "        McGreer_OneSigma = 0.05\n",
    "        if McGreer_NF>McGreer_Mean:\n",
    "            total_sum += np.square((McGreer_Mean - McGreer_NF) / McGreer_OneSigma) # 1side Gaussian\n",
    "\n",
    "\n",
    "        # CMB optical depth\n",
    "        tau_value = model[current_index]\n",
    "        current_index+=1\n",
    "\n",
    "        # Mean and one sigma errors for the Planck constraints, 2006.16828\n",
    "        PlanckTau_Mean = 0.0569\n",
    "        PlanckTau_OneSigma_u = 0.0081\n",
    "        PlanckTau_OneSigma_l = 0.0066\n",
    "        total_sum += np.square( PlanckTau_Mean - tau_value )/(PlanckTau_OneSigma_u * PlanckTau_OneSigma_l +\n",
    "                     (PlanckTau_OneSigma_u - PlanckTau_OneSigma_l) * (tau_value - PlanckTau_Mean))     # one way to write likelihood for 2-side Gaussian\n",
    "\n",
    "        #z=8 and 10 21cm PS\n",
    "        for redshift in [8, 10]:\n",
    "            k_start = np.fromfile('HERA_Phase1_Limits/k_start_z%d.bin'%redshift, dtype=int)[0]\n",
    "            ks = slice(k_start-1, None, 2)\n",
    "            k_limit_vals = np.fromfile('HERA_Phase1_Limits/PS_limit_ks_z%d.bin'%redshift)\n",
    "            kwf_limit_vals = np.fromfile('HERA_Phase1_Limits/PS_limit_kwfs_z%d.bin'%redshift)\n",
    "            Nkbins = len(k_limit_vals)\n",
    "            Nkwfbins = len(kwf_limit_vals)\n",
    "            PS_limit_vals = np.fromfile('HERA_Phase1_Limits/PS_limit_vals_z%d.bin'%redshift)\n",
    "            PS_limit_vars = np.fromfile('HERA_Phase1_Limits/PS_limit_vars_z%d.bin'%redshift)\n",
    "\n",
    "            ModelPS_val = 10**model[current_index:current_index+len(PS_limit_vals)]\n",
    "            current_index+=len(PS_limit_vals)\n",
    "\n",
    "            error_val = np.sqrt(PS_limit_vars + (0.2*ModelPS_val)**2 )\n",
    "            likelihood = 0.5 + 0.5 * scipy.special.erf( ( PS_limit_vals - ModelPS_val ) / (np.sqrt(2) * error_val) ) # another way to write likelihood for 1-side Gaussian\n",
    "            likelihood[likelihood <= 0.0] = 1e-50\n",
    "            total_sum += -2 * np.sum(np.log(likelihood))\n",
    "\n",
    "        # UV LF, still need to interpolate to get the number density at the observed UV magnitudes\n",
    "        for redshift in [6, ]:\n",
    "            fLF = 'LFs/LF_obs_Bouwens_%.6f.txt'%redshift\n",
    "            observation = np.loadtxt(fLF)\n",
    "            observation = observation[observation[:,0]>-20]\n",
    "            modelled_LF = 10**model[current_index:current_index+len(observation)]\n",
    "            current_index+=len(observation)   \n",
    "\n",
    "            total_sum += np.sum(np.square((observation[:,1] - modelled_LF) / observation[:,2]))\n",
    "\n",
    "        return -0.5 * total_sum\n",
    "\n",
    "    sampler = run(\n",
    "        log_likelihood,\n",
    "        Prior,\n",
    "        n_dims=len(limits),\n",
    "        n_params=len(limits),\n",
    "        n_live_points=400,\n",
    "        resume=True,\n",
    "        verbose=True,\n",
    "        write_output=True,\n",
    "        outputfiles_basename='./MultiNest/21CMMCEMU',\n",
    "        max_iter=0,\n",
    "        n_iter_before_update=10,\n",
    "        importance_nested_sampling=False,\n",
    "        multimodal=True,\n",
    "        evidence_tolerance=0.01,\n",
    "        sampling_efficiency=0.9,\n",
    "        init_MPI=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c312431-62cd-4245-8aa3-a3c072eefd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
